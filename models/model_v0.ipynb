{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cluster as skc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Offline Nearest Neighbor processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_keys = pd.read_csv('../Processing/FrameContainer/DataRows/Data_keys.csv', header=None)\n",
    "data_keys = data_keys.iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(0,15):\n",
    "    print(\"Starting recombination for Query Chunk: %d\" % idx)\n",
    "    path = '../Processing/FrameContainer/QueryRows/'\n",
    "    filename = 'Query_Keys_'\n",
    "    currentKeys = pd.read(path + filename + idx + '.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write our files for offline processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pairwise DTF of all \"data-rows\" (10000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_jobs = -1 to turn on parallel\n",
    "start = timer()\n",
    "K = skm.pairwise_kernels(dataRows_df, metric=dtw, n_jobs=1)\n",
    "end = timer()\n",
    "print(end - start)      \n",
    "\n",
    "np.savetxt(\"Processing/DTW_Matrix.out.gz\", K, delimiter=',')\n",
    "\n",
    "# FASTDTW ON SCALE 4E-4 PER PAIR\n",
    "# AT 10^3 SAMPLES, 10^6 ELS, SO 10^2 SECONDS. Tolerance for production up to 10^4 elements \n",
    "# several hours of runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Processing/DTW_Matrix.out.gz\", K, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = np.loadtxt('../Processing/DTW_Matrix.out.gz', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Run Hierarchical clustering on the matrix \n",
    "cluster_ward = skc.AgglomerativeClustering(n_clusters=10, affinity='euclidean', connectivity=K, compute_full_tree=True, linkage='ward')\n",
    "cluster_complete = skc.AgglomerativeClustering(n_clusters=10, affinity='euclidean', connectivity=K, compute_full_tree=True, linkage='complete')\n",
    "cluster_average = skc.AgglomerativeClustering(n_clusters=10, affinity='euclidean', connectivity=K, compute_full_tree=True, linkage='average')\n",
    "\n",
    "\n",
    "\n",
    "labels_ward = cluster_ward.fit_predict(K)\n",
    "labels_complete = cluster_complete.fit_predict(K)\n",
    "labels_average = cluster_average.fit_predict(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
